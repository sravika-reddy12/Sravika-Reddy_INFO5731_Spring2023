{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgY/8myqtO97oBTDqlNJfU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sravika-reddy12/Sravika-Reddy_INFO5731_Spring2023/blob/main/Copy_of_In_class_Exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The In-class-exercise ( 40 points)**"
      ],
      "metadata": {
        "id": "ho36sdYU8TVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question1 : Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data.(10 points)"
      ],
      "metadata": {
        "id": "pg2TUUeF-qh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Please write your answer here:\n",
        "        Question :- \n",
        "What is the review of APPLE iPhone 14 (Midnight, 256 GB).\n",
        "The data required for this study are reviews and ratings from customers who have already purchased, used or are using mobile phones.\n",
        " Check reviews using the Flipkart website. This includes product reviews and ratings. \n",
        "What is the review for this phone. Do you have positive and negative reviews? \n",
        "We can analyze the ratings by looking at the words and rating them on some common words.\n",
        "A minimum of 1000 reviews is required for result.\n",
        "\n",
        "\n",
        "Procedures for collecting and storing data:\n",
        "\n",
        "    *I used the BeautifulSoup library to extract information from a website.\n",
        "    **I used the class name to extract the ratings and added them to an empty list.\n",
        "    ***To extract 1000 reviews, each page has 10 reviews,\n",
        "    ****Generated URLs dynamically by iterating\n",
        "    *****Then I created a dataframe from the list and converted the dataframe to csv \n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "8aW0TuQe_wSI",
        "outputId": "049e370d-e150-42a1-bc9c-d4afb8ca53bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write your answer here:\\n        Question :- \\nWhat is the review of APPLE iPhone 14 (Midnight, 256 GB).\\nThe data required for this study are reviews and ratings from customers who have already purchased, used or are using mobile phones.\\n Check reviews using the Flipkart website. This includes product reviews and ratings. \\nWhat is the review for this phone. Do you have positive and negative reviews? \\nWe can analyze the ratings by looking at the words and rating them on some common words.\\nA minimum of 1000 reviews is required for result.\\n\\n\\nProcedures for collecting and storing data:\\n\\n    *I used the BeautifulSoup library to extract information from a website.\\n    **I used the class name to extract the ratings and added them to an empty list.\\n    ***To extract 1000 reviews, each page has 10 reviews,\\n    ****Generated URLs dynamically by iterating\\n    *****Then I created a dataframe from the list and converted the dataframe to csv \\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question2: Write python code to collect 1000 data samples you discussed above (10 points)"
      ],
      "metadata": {
        "id": "kSsO9eRQAB78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests # start program here\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as DP  # importing\n",
        "a_txt = []\n",
        "p_txt = []\n",
        "for num in range(100):\n",
        "    link = \"https://www.flipkart.com/apple-iphone-14-midnight-256-gb/p/itmdb32e3c997112?pid=MOBGHWFH4H3MMRAA&lid=LSTMOBGHWFH4H3MMRAAO7KNHD&marketplace=FLIPKART&sattr[]=color&sattr[]=storage&st=color\" + str(num)\n",
        "    page = requests.get(link)\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "    main_reviews = soup.find_all(class_='_2-N8zT') # Getting the Review Heading by using the class name\n",
        "    text_reviews = soup.find_all(class_='_3LWZlK _1BLPMq')\n",
        "    # Iterating from list\n",
        "    for ele, sub_ele in zip(main_reviews, text_reviews) : \n",
        "      #Appending\n",
        "        a_txt.append(ele.text) \n",
        "        p_txt.append(sub_ele.text)\n",
        "        #Dataframe creation\n",
        "df = DP.DataFrame(list(zip(a_txt, p_txt)), columns =['Review', 'Rating'])  \n",
        "#print statement\n",
        "print(\"Length of data frame is {0}\".format(len(df)))\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "naG1QDShB2Gd",
        "outputId": "ceeb0a99-6a07-42d9-ce69-478876486f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data frame is 1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Review Rating\n",
              "0              Fabulous!      5\n",
              "1          Great product      5\n",
              "2    Best in the market!      5\n",
              "3              Must buy!      5\n",
              "4              Fabulous!      5\n",
              "..                   ...    ...\n",
              "995     Perfect product!      5\n",
              "996       Classy product      5\n",
              "997            Fabulous!      5\n",
              "998   Highly recommended      5\n",
              "999         Nice product      4\n",
              "\n",
              "[1000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0474469d-5c72-40ca-8e05-493fcebfe99f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great product</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Must buy!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Perfect product!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Classy product</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Highly recommended</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Nice product</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0474469d-5c72-40ca-8e05-493fcebfe99f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0474469d-5c72-40ca-8e05-493fcebfe99f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0474469d-5c72-40ca-8e05-493fcebfe99f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3 : Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).(10 points)\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ],
      "metadata": {
        "id": "iHtLYuypCKni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# writing the code here\n",
        "\n",
        "key_word = \"information retrieval\"\n",
        "\n",
        "#information retrieval\n",
        "key_word_format = \"+\".join(key_word.split(\" \"))\n",
        "\n",
        "\n",
        "check_link =\"https://dl.acm.org/action/doSearch?AllField=\" + key_word_format + \"&pageSize=50&startPage=\" \n"
      ],
      "metadata": {
        "id": "1z5-wh7gzZmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hgv-r4_vzeaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsqLWIlkgLW7",
        "outputId": "af56a5b2-0d5b-4a30-aaa0-60310931a013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page:  37\n",
            "page:  43\n"
          ]
        }
      ],
      "source": [
        "Req_df = DP.DataFrame(columns = [\"Title\", \"Venue/Journal/Conf\", \"Year\", \"Authors\", \"Abstract\"])\n",
        "#for loop\n",
        "for i in range(1,200):\n",
        "#try block\n",
        "#using beautiful soup\n",
        "    try:\n",
        "        search_link = check_link + str(i)\n",
        "        page = requests.get(search_link)\n",
        "        soup = BeautifulSoup(page.text, 'html.parser')\n",
        "        titles = soup.find_all(class_ = \"hlFld-Title\")\n",
        "# for loop\n",
        "        for j in titles:\n",
        "#if condition\n",
        "            if len(Req_df) < 1001:       \n",
        "                sub_link = \"https://dl.acm.org\" + j.find(\"a\").get(\"href\")\n",
        "                sub_page = requests.get(sub_link)\n",
        "                sub_soup = BeautifulSoup(sub_page.text, 'html.parser')\n",
        "                year_j = sub_soup.find_all(class_ = \"CitationCoverDate\")[0].text.split(\" \")[-1]\n",
        "                if 2011 < int(year_j) < 2023:\n",
        "                    Req_df = Req_df.append({\n",
        "                        \"Title\"              : sub_soup.find_all(class_ = \"citation__title\")[0].text,\n",
        "                        \"Venue/Journal/Conf\" : sub_soup.find_all(class_ = \"issue-item__detail\")[0].find(\"a\").get(\"title\"),\n",
        "                        \"Year\"               : year_j,\n",
        "                        \"Authors\"            : sub_soup.find_all(class_ = \"author-data\")[0].text,\n",
        "                        \"Abstract\"           : sub_soup.find_all(class_ = \"hlFld-Abstract\")[0].text[8:].replace(\"\\n\", \"\")\n",
        "                    }, ignore_index = True)\n",
        "                #sub_page.close()\n",
        "                # else block\n",
        "                # break statement\n",
        "            else:\n",
        "                break\n",
        "    except:\n",
        "        print(\"page: \", i)\n",
        "    #page.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBM5Db-cgLW7",
        "outputId": "98eb18b7-0a26-44d7-b3e3-3269b14e22ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Venue/Journal/Conf</th>\n",
              "      <th>Year</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Interactive Information Retrieval with Bandit ...</td>\n",
              "      <td>SIGIR '21: Proceedings of the 44th Internation...</td>\n",
              "      <td>2021</td>\n",
              "      <td>Huazheng Wang</td>\n",
              "      <td>Information retrieval (IR) in nature is a proc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Proactive Information Retrieval via Screen Sur...</td>\n",
              "      <td>SIGIR '17: Proceedings of the 40th Internation...</td>\n",
              "      <td>2017</td>\n",
              "      <td>Tung Vuong</td>\n",
              "      <td>We demonstrate proactive information retrieval...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Private Stateful Information Retrieval</td>\n",
              "      <td>CCS '18: Proceedings of the 2018 ACM SIGSAC Co...</td>\n",
              "      <td>2018</td>\n",
              "      <td>Sarvar Patel</td>\n",
              "      <td>Private information retrieval (PIR) is a funda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Crowdsourcing for information retrieval</td>\n",
              "      <td>ACM SIGIR Forum</td>\n",
              "      <td>2012</td>\n",
              "      <td>Matthew Lease</td>\n",
              "      <td>The 2nd SIGIR Workshop on Crowdsourcing for In...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bandit Algorithms in Interactive Information R...</td>\n",
              "      <td>ICTIR '17: Proceedings of the ACM SIGIR Intern...</td>\n",
              "      <td>2017</td>\n",
              "      <td>Dorota Glowacka</td>\n",
              "      <td>The multi-armed bandit problem models an agent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>Report on the SIGIR 2013 workshop on modeling ...</td>\n",
              "      <td>ACM SIGIR Forum</td>\n",
              "      <td>2013</td>\n",
              "      <td>Charles L.A. Clarke</td>\n",
              "      <td>The SIGIR 2013 Workshop on Modeling User Behav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>Effective Information Retrieval Approach based...</td>\n",
              "      <td>ICARCSET '15: Proceedings of the 2015 Internat...</td>\n",
              "      <td>2015</td>\n",
              "      <td>I. Govindharaj</td>\n",
              "      <td>The Information technology is developing rapid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>A user defined taxonomy of factors that divide...</td>\n",
              "      <td>IIiX '14: Proceedings of the 5th Information I...</td>\n",
              "      <td>2014</td>\n",
              "      <td>Chaoyu Ye</td>\n",
              "      <td>Although research is increasingly interested i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>Report on the fifth workshop on exploiting sem...</td>\n",
              "      <td>ACM SIGIR Forum</td>\n",
              "      <td>2012</td>\n",
              "      <td>Jaap Kamps</td>\n",
              "      <td>There is an increasing amount of structure on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>Towards an Optimal Dialog Strategy for Informa...</td>\n",
              "      <td>IUI '18: 23rd International Conference on Inte...</td>\n",
              "      <td>2018</td>\n",
              "      <td>Yunfeng Zhang</td>\n",
              "      <td>The emerging paradigm of dialogue interfaces f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>528 rows √ó 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Title  \\\n",
              "0    Interactive Information Retrieval with Bandit ...   \n",
              "1    Proactive Information Retrieval via Screen Sur...   \n",
              "2               Private Stateful Information Retrieval   \n",
              "3              Crowdsourcing for information retrieval   \n",
              "4    Bandit Algorithms in Interactive Information R...   \n",
              "..                                                 ...   \n",
              "523  Report on the SIGIR 2013 workshop on modeling ...   \n",
              "524  Effective Information Retrieval Approach based...   \n",
              "525  A user defined taxonomy of factors that divide...   \n",
              "526  Report on the fifth workshop on exploiting sem...   \n",
              "527  Towards an Optimal Dialog Strategy for Informa...   \n",
              "\n",
              "                                    Venue/Journal/Conf  Year  \\\n",
              "0    SIGIR '21: Proceedings of the 44th Internation...  2021   \n",
              "1    SIGIR '17: Proceedings of the 40th Internation...  2017   \n",
              "2    CCS '18: Proceedings of the 2018 ACM SIGSAC Co...  2018   \n",
              "3                                      ACM SIGIR Forum  2012   \n",
              "4    ICTIR '17: Proceedings of the ACM SIGIR Intern...  2017   \n",
              "..                                                 ...   ...   \n",
              "523                                    ACM SIGIR Forum  2013   \n",
              "524  ICARCSET '15: Proceedings of the 2015 Internat...  2015   \n",
              "525  IIiX '14: Proceedings of the 5th Information I...  2014   \n",
              "526                                    ACM SIGIR Forum  2012   \n",
              "527  IUI '18: 23rd International Conference on Inte...  2018   \n",
              "\n",
              "                 Authors                                           Abstract  \n",
              "0          Huazheng Wang  Information retrieval (IR) in nature is a proc...  \n",
              "1             Tung Vuong  We demonstrate proactive information retrieval...  \n",
              "2           Sarvar Patel  Private information retrieval (PIR) is a funda...  \n",
              "3          Matthew Lease  The 2nd SIGIR Workshop on Crowdsourcing for In...  \n",
              "4        Dorota Glowacka  The multi-armed bandit problem models an agent...  \n",
              "..                   ...                                                ...  \n",
              "523  Charles L.A. Clarke  The SIGIR 2013 Workshop on Modeling User Behav...  \n",
              "524       I. Govindharaj  The Information technology is developing rapid...  \n",
              "525            Chaoyu Ye  Although research is increasingly interested i...  \n",
              "526           Jaap Kamps  There is an increasing amount of structure on ...  \n",
              "527        Yunfeng Zhang  The emerging paradigm of dialogue interfaces f...  \n",
              "\n",
              "[528 rows x 5 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Req_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data.(10 points)\n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text"
      ],
      "metadata": {
        "id": "-HuaXhtq7K8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pKHtaqGgLW7",
        "outputId": "f7d8c5b3-0585-4d83-8dd8-0d78bfb1d855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: snscrape in c:\\users\\manis\\anaconda3\\lib\\site-packages (0.4.3.20220106)\n",
            "Requirement already satisfied: requests[socks] in c:\\users\\manis\\anaconda3\\lib\\site-packages (from snscrape) (2.25.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\manis\\anaconda3\\lib\\site-packages (from snscrape) (3.0.12)\n",
            "Requirement already satisfied: lxml in c:\\users\\manis\\anaconda3\\lib\\site-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: pytz in c:\\users\\manis\\anaconda3\\lib\\site-packages (from snscrape) (2021.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from snscrape) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.26.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "#Writing the code here\n",
        "#pip installing snscrape\n",
        "!pip install snscrape\n",
        "#Importing snscrape.modules.twitter\n",
        "import snscrape.modules.twitter as sntwitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdlNct_fgLW8"
      },
      "outputs": [],
      "source": [
        "attributes_container = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNwLmRNYgLW8"
      },
      "outputs": [],
      "source": [
        "#for loop\n",
        "\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('data since:2021-01-01 until:2022-09-20').get_items()):\n",
        "    if i>1000:\n",
        "        break\n",
        "    attributes_container.append([tweet.user.username, tweet.date, tweet.content])\n",
        "# if statement\n",
        "# break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWhL9dlggLW8",
        "outputId": "43d6c995-21e1-4f0a-ef25-2a82ed80a124"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Date Created</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tigerladytexas</td>\n",
              "      <td>2022-09-19 23:59:59+00:00</td>\n",
              "      <td>@RoxineKing @AZ_Brittney Where did they get th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>davesnyder</td>\n",
              "      <td>2022-09-19 23:59:59+00:00</td>\n",
              "      <td>@bernardjhuang Be able to build briefs as part...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ProdukPantau</td>\n",
              "      <td>2022-09-19 23:59:59+00:00</td>\n",
              "      <td>Coba cek ini, deh: \"UNEED Nylon Kabel Data Typ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MLB_DATA_</td>\n",
              "      <td>2022-09-19 23:59:59+00:00</td>\n",
              "      <td>Julio Teheran(ATL) Age.24\\n33ÁôªÊùø11Âãù8Êïó\\nÈò≤Âæ°Áéá4.04\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cereja_stranger</td>\n",
              "      <td>2022-09-19 23:59:59+00:00</td>\n",
              "      <td>Todo dia uma foto aleat√≥ria at√© falarem a data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>data_diario</td>\n",
              "      <td>2022-09-19 23:39:22+00:00</td>\n",
              "      <td>üí• @CFKArgentina, sobre la Causa Vialidad: \"Vam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>curtisbuzzard</td>\n",
              "      <td>2022-09-19 23:39:21+00:00</td>\n",
              "      <td>Great session on data literacy at the Maneuver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>bookstand171</td>\n",
              "      <td>2022-09-19 23:39:21+00:00</td>\n",
              "      <td>fetterman of pennsylvania and biden of delawar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>info_daratan</td>\n",
              "      <td>2022-09-19 23:39:20+00:00</td>\n",
              "      <td>Idrus memuji kinerja KPU khususnya terkait kew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>homo10sapiens</td>\n",
              "      <td>2022-09-19 23:39:20+00:00</td>\n",
              "      <td>A pesquisa data Povo √© real! E mostra outra re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1001 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 User              Date Created  \\\n",
              "0      tigerladytexas 2022-09-19 23:59:59+00:00   \n",
              "1          davesnyder 2022-09-19 23:59:59+00:00   \n",
              "2        ProdukPantau 2022-09-19 23:59:59+00:00   \n",
              "3           MLB_DATA_ 2022-09-19 23:59:59+00:00   \n",
              "4     cereja_stranger 2022-09-19 23:59:59+00:00   \n",
              "...               ...                       ...   \n",
              "996       data_diario 2022-09-19 23:39:22+00:00   \n",
              "997     curtisbuzzard 2022-09-19 23:39:21+00:00   \n",
              "998      bookstand171 2022-09-19 23:39:21+00:00   \n",
              "999      info_daratan 2022-09-19 23:39:20+00:00   \n",
              "1000    homo10sapiens 2022-09-19 23:39:20+00:00   \n",
              "\n",
              "                                                  Tweet  \n",
              "0     @RoxineKing @AZ_Brittney Where did they get th...  \n",
              "1     @bernardjhuang Be able to build briefs as part...  \n",
              "2     Coba cek ini, deh: \"UNEED Nylon Kabel Data Typ...  \n",
              "3     Julio Teheran(ATL) Age.24\\n33ÁôªÊùø11Âãù8Êïó\\nÈò≤Âæ°Áéá4.04\\...  \n",
              "4     Todo dia uma foto aleat√≥ria at√© falarem a data...  \n",
              "...                                                 ...  \n",
              "996   üí• @CFKArgentina, sobre la Causa Vialidad: \"Vam...  \n",
              "997   Great session on data literacy at the Maneuver...  \n",
              "998   fetterman of pennsylvania and biden of delawar...  \n",
              "999   Idrus memuji kinerja KPU khususnya terkait kew...  \n",
              "1000  A pesquisa data Povo √© real! E mostra outra re...  \n",
              "\n",
              "[1001 rows x 3 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_df = DP.DataFrame(attributes_container, columns=[\"User\", \"Date Created\", \"Tweet\"])\n",
        "tweets_df\n",
        "#tweets_df"
      ]
    }
  ]
}