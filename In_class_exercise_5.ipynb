{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sravika-reddy12/Sravika-Reddy_INFO5731_Spring2023/blob/main/In_class_exercise_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTXWEy54yDzc"
      },
      "source": [
        "# **The fifth in-class-exercise \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5INJbGdyyDzd"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "(7) Word2Vec\n",
        "\n",
        "(8) BERT\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "with open(\"stsa-train.txt\") as txt:\n",
        "  mylist_test = [line.rstrip('\\n') for line in txt]\n",
        "\n",
        "labels_train = []\n",
        "text_train = []\n",
        "\n",
        "for line in mylist_test:\n",
        "  label_train, text = line.split(' ', 1)\n",
        "  labels_train.append(int(label_train))\n",
        "  text_train.append(text)\n",
        "\n",
        "dataset_train = pd.DataFrame(list(zip(labels_train, text_train)), columns=['Reviews', 'Text'])\n",
        "dataset_train.head()\n",
        "\n",
        "with open(\"stsa-test.txt\") as txt:\n",
        "  mylist_test = [line.rstrip('\\n') for line in txt]\n",
        "\n",
        "labels_test = []\n",
        "text_test = []\n",
        "\n",
        "for line in mylist_test:\n",
        "  label_test, text = line.split(' ', 1)\n",
        "  labels_test.append(int(label_test))\n",
        "  text_test.append(text)\n",
        "\n",
        "dataset_test = pd.DataFrame(list(zip(labels_test, text_test)), columns=['Reviews', 'Text'])\n",
        "dataset_test.head()"
      ],
      "metadata": {
        "id": "3wPcjZV-AzmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R8ZWsxElyDze"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Write your code here\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZxbRrln4Lx2"
      },
      "source": [
        "Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "2weU5-nLzIit",
        "outputId": "262209d0-7bfc-481f-8c8c-1900e419a09d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-95a3203ec0b8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stsa-train.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxtf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmylist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxtf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stsa-train.txt'"
          ]
        }
      ],
      "source": [
        "with open(\"stsa-train.txt\") as txtf:\n",
        "    mylist = [line.rstrip('\\n') for line in txtf]\n",
        "    \n",
        "labels = []\n",
        "text = []\n",
        "\n",
        "for i, line in enumerate(mylist):\n",
        "    label = mylist[i][0]\n",
        "    tex = mylist[i][1:]\n",
        "    labels.append(label)\n",
        "    text.append(tex)\n",
        "\n",
        "dataset = pd.DataFrame(list(zip(labels, text)),columns =['Reviews', 'Text'])\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UsMSawd4Qov"
      },
      "source": [
        "Training data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y807xE1QzY0J",
        "outputId": "46abe49d-6a4a-410e-baaf-7f064990f437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] bcp47............... BCP-47 Language Tags\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence=str(sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence=sentence.replace('{html}',\"\") \n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(rem_num)  \n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "dataset['cleanText']=dataset['Text'].map(lambda s:preprocess(s)) \n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNcING8L4VkU"
      },
      "source": [
        "Testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEqSTglkzqOI"
      },
      "outputs": [],
      "source": [
        "with open(\"stsa-test.txt\") as txtf:\n",
        "    mylist_test = [line.rstrip('\\n') for line in txtf]\n",
        "    \n",
        "labels_test = []\n",
        "text_test = []\n",
        "\n",
        "for i, line in enumerate(mylist_test):\n",
        "    label_test = mylist_test[i][0]\n",
        "    tex_test = mylist_test[i][1:]\n",
        "    labels_test.append(label_test)\n",
        "    text_test.append(tex_test)\n",
        "\n",
        "dataset_test = pd.DataFrame(list(zip(labels_test, text_test)),columns =['Reviews', 'Text'])\n",
        "dataset_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghSQzHCf4ZKk"
      },
      "source": [
        "Testing data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOu7Ky98zvVI"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence=str(sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence=sentence.replace('{html}',\"\") \n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(rem_num)  \n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "dataset_test['cleanText']=dataset_test['Text'].map(lambda s:preprocess(s)) \n",
        "dataset_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy4bu9xD4rWD"
      },
      "source": [
        "TF-IDF Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ybt4o_1zzbw"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase = False, analyzer='word')\n",
        "train_tfidf = tfidf_vectorizer.fit_transform(dataset[\"cleanText\"]).toarray()\n",
        "test_tfidf = tfidf_vectorizer.transform(dataset_test[\"cleanText\"]).toarray()\n",
        "x_test = test_tfidf\n",
        "y_test = dataset_test[\"Reviews\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvBWCsJr4w9N"
      },
      "source": [
        "Data partitioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUMmbdp6z3rL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train_tfidf,dataset[\"Reviews\"],test_size = 0.2, random_state = 202)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvvuETSc0AL6"
      },
      "source": [
        "Algorithms\n",
        "\n",
        "\n",
        "1.MultinominalNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKIcTEla0MHe"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "model = classifier.fit(x_train, y_train) \n",
        "predictions_validation_set = classifier.predict(x_valid) \n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print (\"Accuracy of the Naive Bayes model on validation set is : \", round(accuracy_score(y_valid, predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRjZORMf0RBK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_naive_validation = classification_report(y_valid, predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMa0KRA30V9L"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "naive_accuracies_validation = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Naive Bayes Model  10-fold cross validation score on training set is :  {round(naive_accuracies_validation.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mfg53IIO0XBS"
      },
      "outputs": [],
      "source": [
        "predictions_test_set = classifier.predict(x_test) \n",
        "print (\"Accuracy of the Naive Bayes model on test set is : \", round(accuracy_score(y_test, predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImepsQ_J0aW6"
      },
      "outputs": [],
      "source": [
        "cr_naive_test = classification_report(y_test, predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpJ6Hwsx0Ifc"
      },
      "outputs": [],
      "source": [
        "naive_accuracies_test = cross_val_score(estimator = classifier, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Naive Bayes Model 10-fold cross validation score on testing set is :  {round(naive_accuracies_test.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW5PlNFu0myj"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3AUgGvo0oA2"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "classifier_svm = svm.SVC()\n",
        "model_svm = classifier_svm.fit(x_train, y_train) \n",
        "svm_predictions_validation_set = classifier_svm.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the SVM model on validation set is : \", round(accuracy_score(y_valid, svm_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGcsv9JR0rm_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_svm_validation = classification_report(y_valid, svm_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z80OukX0uUS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "svm_accuracies_validation = cross_val_score(estimator = classifier_svm, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"SVM Model  10-fold cross validation score on training set is :  {round(svm_accuracies_validation.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfkwS-VI0xXx"
      },
      "outputs": [],
      "source": [
        "svm_predictions_test_set = classifier_svm.predict(x_test) \n",
        "print (\"Accuracy of the SVM model on test set is : \", round(accuracy_score(y_test, svm_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EVQWP0z03zi"
      },
      "outputs": [],
      "source": [
        "cr_svm_test = classification_report(y_test, svm_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cZTjR1Y06qt"
      },
      "outputs": [],
      "source": [
        "svm_accuracies_test = cross_val_score(estimator = classifier_svm, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"SVM Model 10-fold cross validation score on testing set is :  {round(svm_accuracies_test.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-LioMZS1ABN"
      },
      "source": [
        "KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5r-YGRL1A_B"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifier_knn = KNeighborsClassifier(n_neighbors = 15)\n",
        "model_knn = classifier_knn.fit(x_train, y_train) \n",
        "knn_predictions_validation_set = classifier_knn.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the KNN model on validation set is : \", round(accuracy_score(y_valid, knn_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppUiM6n_1GZA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_knn_validation = classification_report(y_valid, knn_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB1sSJCC1YCJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "knn_accuracies_validation = cross_val_score(estimator = classifier_knn, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"KNN Model  10-fold cross validation score on training set is :  {round(knn_accuracies_validation.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUajO9Pv1cYN"
      },
      "outputs": [],
      "source": [
        "knn_predictions_test_set = classifier_knn.predict(x_test) \n",
        "print (\"Accuracy of the KNN model on test set is : \", round(accuracy_score(y_test, knn_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GSWKwUq1f02"
      },
      "outputs": [],
      "source": [
        "cr_knn_test = classification_report(y_test, knn_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdOIqaf61jKF"
      },
      "outputs": [],
      "source": [
        "\n",
        "knn_accuracies_test = cross_val_score(estimator = classifier_knn, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"KNN Model 10-fold cross validation score on testing set is :  {round(knn_accuracies_test.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3rO8sJ61rJr"
      },
      "source": [
        "Decison Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b64kRVRn1odt"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifier_dt = DecisionTreeClassifier()\n",
        "model_dt = classifier_dt.fit(x_train, y_train) \n",
        "dt_predictions_validation_set = classifier_dt.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the Decison Tree Classifier model on validation set is : \", round(accuracy_score(y_valid, dt_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybiqJWX61_O_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_dt_validation = classification_report(y_valid, dt_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSkbk_Rv2Cqw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "dt_accuracies_validation = cross_val_score(estimator = classifier_dt, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Decison Tree Classifier Model  10-fold cross validation score on training set is :  {round(dt_accuracies_validation.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiF0IgP02DmX"
      },
      "outputs": [],
      "source": [
        "dt_predictions_test_set = classifier_dt.predict(x_test) \n",
        "print (\"Accuracy of the Decison Tree Classifier model on test set is : \", round(accuracy_score(y_test, dt_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iz8cfr32L1T"
      },
      "outputs": [],
      "source": [
        "cr_dt_test = classification_report(y_test, dt_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rua1f8XD2Ml2"
      },
      "outputs": [],
      "source": [
        "dt_accuracies_test = cross_val_score(estimator = classifier_dt, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Decison Tree Classifier Model 10-fold cross validation score on testing set is :  {round(dt_accuracies_test.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnDAWgAI2St2"
      },
      "source": [
        "Randomforest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0uttK3c2Tl0"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier_rf = RandomForestClassifier()\n",
        "model_rf = classifier_rf.fit(x_train, y_train) \n",
        "rf_predictions_validation_set = classifier_rf.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the Random Forest Classifier model on validation set is : \", round(accuracy_score(y_valid, rf_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the Random Forest Classifier model on validation set is : \", round(precision_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Random Forest Classifier model on validation set is : \", round(recall_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Random Forest Classifier model on validation set is : \", round(f1_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVnt-0_X2XRz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_rf_validation = classification_report(y_valid, rf_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3Q04Pfz2aM_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "rf_accuracies_validation = cross_val_score(estimator = classifier_rf, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Decison Random Forest Model  10-fold cross validation score on training set is :  {round(rf_accuracies_validation.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leeU5Spq2efs"
      },
      "outputs": [],
      "source": [
        "rf_predictions_test_set = classifier_rf.predict(x_test) \n",
        "print (\"Accuracy of the Random Forest Classifier model on test set is : \", round(accuracy_score(y_test, rf_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the Random Forest Classifier model on validation set is : \", round(precision_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Random Forest Classifier model on validation set is : \", round(recall_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Random Forest Classifier model on validation set is : \", round(f1_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZL922nB2im-"
      },
      "outputs": [],
      "source": [
        "cr_rf_test = classification_report(y_test, rf_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sw2YXgs2nRS"
      },
      "outputs": [],
      "source": [
        "rf_accuracies_test = cross_val_score(estimator = classifier_rf, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Random Forest Classifier Model 10-fold cross validation score on testing set is :  {round(rf_accuracies_test.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDx2dHbl2p-s"
      },
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8kUKRxa2qz5"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "classifier_xgb = XGBClassifier()\n",
        "model_xgb = classifier_xgb.fit(x_train, y_train) \n",
        "xgb_predictions_validation_set = classifier_xgb.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the XGBoost Classifier model on validation set is : \", round(accuracy_score(y_valid, xgb_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the XGBoost Classifier model on validation set is : \", round(precision_score(y_valid, xgb_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the XGBoost Classifier model on validation set is : \", round(recall_score(y_valid, xgb_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the XGBoost Classifier model on validation set is : \", round(f1_score(y_valid, xgb_predictions_validation_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3tgI3vt2uJw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_xgb_validation = classification_report(y_valid, xgb_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_xgb_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "725YjYdZ2xE3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "xgb_accuracies_validation = cross_val_score(estimator = classifier_xgb, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"XGBoost Model  10-fold cross validation score on training set is :  {round(xgb_accuracies_validation.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W240lE7220WK"
      },
      "outputs": [],
      "source": [
        "xgb_predictions_test_set = classifier_xgb.predict(x_test) \n",
        "print (\"Accuracy of the XGBoost Classifier model on test set is : \", round(accuracy_score(y_test, xgb_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the XGBoost Classifier model on validation set is : \", round(precision_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the XGBoost Classifier model on validation set is : \", round(recall_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the XGBoost Classifier model on validation set is : \", round(f1_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl0dMjxM24h2"
      },
      "outputs": [],
      "source": [
        "cr_xgb_test = classification_report(y_test, xgb_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_xgb_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISP47VyK27eU"
      },
      "outputs": [],
      "source": [
        "xgb_accuracies_test = cross_val_score(estimator = classifier_xgb, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"XGBoost Classifier Model 10-fold cross validation score on testing set is :  {round(xgb_accuracies_test.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNn7F8Am2-R-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-NQem_YyDze"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K-means\n",
        "\n",
        "DBSCAN\n",
        "\n",
        "Hierarchical clustering\n",
        "\n",
        "Word2Vec\n",
        "\n",
        "BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuO8_ehy3Dhx"
      },
      "source": [
        "K MEANS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCE9EXfAyDzf"
      },
      "outputs": [],
      "source": [
        "#Write your code here.\n",
        "df = pd.read_csv('Amazon_Unlocked_Mobile1.csv')\n",
        "\n",
        "df['Reviews']=df['Reviews'].map(lambda s:preprocess(s)) \n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mr0MU-L3GuJ"
      },
      "outputs": [],
      "source": [
        "# TF-IDF VECTORIZATION\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vects = tfidf_vect.fit_transform(df['Reviews'].values.astype('U'))\n",
        "names= tfidf_vect.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPolXN_N3Jv8"
      },
      "outputs": [],
      "source": [
        "## ELBOW METHOD\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(2,12):\n",
        "    kmeans = KMeans(n_clusters = i, init = \"k-means++\", random_state = 101)\n",
        "    kmeans.fit(tfidf_vects)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize = (11,6))\n",
        "plt.plot(range(2,12), wcss, marker = \"o\")\n",
        "plt.title (\"The Elbow Method\")\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"WCSS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2gkueDx3Mrl"
      },
      "outputs": [],
      "source": [
        "#forming 6 clusters\n",
        "from sklearn.cluster import KMeans\n",
        "model = KMeans(n_clusters = 6,init='k-means++',max_iter=10000, random_state=50)\n",
        "model.fit(tfidf_vects)\n",
        "from collections import Counter\n",
        "Counter(model.labels_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psq-MQqR3P-5"
      },
      "outputs": [],
      "source": [
        "# Clusters containing words with maximum strength\n",
        "top_words = 7\n",
        "centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "for cluster_num in range(6):\n",
        "    key_features = [names[i] for i in centroids[cluster_num, :top_words]]\n",
        "    print('Cluster '+str(cluster_num+1))\n",
        "    print('Top Words:', key_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnm_CTUj3SNU"
      },
      "outputs": [],
      "source": [
        "cluster_center=model.cluster_centers_\n",
        "cluster_center"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCAsEBh_3W4P"
      },
      "source": [
        "DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrjkbPaq3UwN"
      },
      "outputs": [],
      "source": [
        "reviews=[]\n",
        "for i in df['Reviews']:\n",
        "    reviews.append(str(i).split())\n",
        "import gensim\n",
        "w2v_model=gensim.models.Word2Vec(reviews, size=100, workers=4)\n",
        "\n",
        "import numpy as np\n",
        "vectors = []\n",
        "for i in reviews:\n",
        "    vector = np.zeros(100)\n",
        "    count = 0\n",
        "    for word in i:\n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            vector += vec\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    vector /= count\n",
        "    vectors.append(vector)  \n",
        "vectors = np.array(vectors)\n",
        "vectors = np.nan_to_num(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml_FH60a3ay3"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "minPts = 2 * 100\n",
        "# Lower bound function\n",
        "def lower_bound(nums, target): \n",
        "    l, r = 0, len(nums) - 1\n",
        "    # Binary searching\n",
        "    while l <= r:\n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= target:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l\n",
        "\n",
        "def compute200thnearestneighbour(x, data): \n",
        "    dists = []\n",
        "    for val in data:\n",
        "      # computing distances\n",
        "        dist = np.sum((x - val) **2 ) \n",
        "        if(len(dists) == 200 and dists[199] > dist): \n",
        "            l = int(lower_bound(dists, dist)) \n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "        else:\n",
        "            dists.append(dist)\n",
        "            dists.sort()\n",
        "\n",
        "# Dist 199 contains the distance of 200th nearest neighbour.    \n",
        "    return dists[199]\n",
        "\n",
        "vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKIvwQgx3e9T"
      },
      "outputs": [],
      "source": [
        "# Computing the 200th nearest neighbour distance of some point the dataset:\n",
        "twohundrethneigh = []\n",
        "for val in vectors[:1000]:\n",
        "    twohundrethneigh.append( compute200thnearestneighbour(val, vectors[:1000]) )\n",
        "twohundrethneigh.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmcmTe4v3htb"
      },
      "outputs": [],
      "source": [
        "# Plotting for the Elbow Method :\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(14,4))\n",
        "plt.title(\"Elbow Method for Finding the right Eps hyperparameter\")\n",
        "plt.plot([x for x in range(len(twohundrethneigh))], twohundrethneigh)\n",
        "plt.xlabel(\"Number of points\")\n",
        "plt.ylabel(\"Distance of 200th Nearest Neighbour\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHkJQjEJ3kp9"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "model_dbs = DBSCAN(eps = 5, min_samples = minPts)\n",
        "model_dbs.fit(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB4_7k0B3naO"
      },
      "outputs": [],
      "source": [
        "df_dbs = df\n",
        "df_dbs[\"DBS Cluster Label\"] = model_dbs.labels_\n",
        "df_dbs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXhghHcl3sjY"
      },
      "source": [
        "Hierarchical clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5gINuz_3p7h"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy.cluster import hierarchy\n",
        "dendro=hierarchy.dendrogram(hierarchy.linkage(vectors,method='ward'))\n",
        "plt.axhline(y=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSu3_4eo3vtD"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  #took n=3 from dendrogram curve \n",
        "Agg=cluster.fit_predict(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_45BLq33y1i"
      },
      "outputs": [],
      "source": [
        "df['AVG-W2V Clus Label'] = cluster.labels_\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjXBRG8w34Rz"
      },
      "outputs": [],
      "source": [
        "hier_df = df # Give the labels and group to count the number of data in each clusters.\n",
        "hier_df[\"Hierarchial Cluster Labels\"] = cluster.labels_\n",
        "hier_df.groupby([\"Hierarchial Cluster Labels\"])[\"Reviews\"].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5lLuKQXyDzf"
      },
      "source": [
        "In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkNMYZhFyDzf"
      },
      "outputs": [],
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}